import * as ort from 'onnxruntime-web'
import type { ModelInfo, ONNXSessionOptions } from '../types/index.ts'
import { ImageProcessor } from './imageProcessor.ts'

/**
 * ONNX Runtime Web æ¨ç†å·¥å…·ç±»
 * æ”¯æŒWebGPU/WebNNåç«¯çš„Real-ESRGANæ¨¡å‹æ¨ç†
 */
// æ¨¡å‹é…ç½®æ¥å£
interface ModelConfig {
  id: string
  name: string
  path: string
  description: string
  scaleFactor: number
  inputSize: number
  minInputSize?: number
}

export class ONNXInference {
  private session: ort.InferenceSession | null = null
  public isInitialized: boolean = false
  private modelInfo: ModelInfo | null = null
  private originalImageSize: { width: number, height: number } | null = null
  private currentModelConfig: ModelConfig | null = null

  constructor() {
    this.session = null
    this.isInitialized = false
    this.modelInfo = null
    this.originalImageSize = null
    this.currentModelConfig = null
  }

  /**
   * åˆå§‹åŒ–ONNX Runtimeå’Œæ¨¡å‹
   */
  async initialize(
    modelPath: string, 
    progressCallback?: (progress: number) => void, 
    modelConfig?: ModelConfig
  ): Promise<boolean> {
    try {
      // ä¿å­˜æ¨¡å‹é…ç½®
      this.currentModelConfig = modelConfig || null
      
      // é…ç½®ONNX Runtime
      await this.configureORT()
      
      if (progressCallback) progressCallback(20)

      // åŠ è½½æ¨¡å‹
      await this.loadModel(modelPath, progressCallback)
      
      if (progressCallback) progressCallback(100)
      
      this.isInitialized = true
      console.log(`ONNXæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: ${modelConfig?.name || 'æœªçŸ¥æ¨¡å‹'}`)
      return true
    } catch (error) {
      console.error('ONNXæ¨¡å‹åˆå§‹åŒ–å¤±è´¥:', error)
      // ä¸å†æŠ›å‡ºé”™è¯¯ï¼Œè®©åº”ç”¨ç»§ç»­è¿è¡Œ
      this.isInitialized = false
      return false
    }
  }

  /**
   * é…ç½®ONNX Runtime - ä¼˜åŒ–æ€§èƒ½å’Œå‡å°‘é˜»å¡
   */
  private async configureORT(): Promise<void> {
    try {
      // è®¾ç½®åŸºç¡€é…ç½®
      ort.env.logLevel = 'warning'
      
      // ä¼˜åŒ–çš„WASMé…ç½® - æå‡æ€§èƒ½
      const maxThreads = Math.min(4, navigator.hardwareConcurrency || 2)
      ort.env.wasm.numThreads = maxThreads // ä½¿ç”¨å¤šçº¿ç¨‹æå‡æ€§èƒ½
      ort.env.wasm.simd = true // å¯ç”¨SIMDæŒ‡ä»¤
      
      console.log(`ğŸ”§ ONNX Runtimeé…ç½®: ${maxThreads}ä¸ªçº¿ç¨‹, SIMDå·²å¯ç”¨`)
      
      // æ£€æµ‹ç¡¬ä»¶èƒ½åŠ›
      const capabilities = await this.detectHardwareCapabilities()
      console.log('ğŸ–¥ï¸ ç¡¬ä»¶èƒ½åŠ›æ£€æµ‹:', capabilities)
      
    } catch (error) {
      console.warn('ONNX Runtimeé…ç½®å¤±è´¥:', error)
      // é™çº§é…ç½®
      ort.env.wasm.numThreads = 1
    }
  }

  /**
   * åŠ è½½ONNXæ¨¡å‹
   */
  private async loadModel(modelPath: string, progressCallback?: (progress: number) => void): Promise<void> {
    let lastError: Error | null = null
    
    // æ™ºèƒ½é€‰æ‹©æ‰§è¡Œæä¾›è€… - ä¼˜å…ˆGPUåŠ é€Ÿé¿å…ä¸»çº¿ç¨‹é˜»å¡
    const capabilities = await this.detectHardwareCapabilities()
    const providerConfigs: string[][] = []
    
    // ä¼˜å…ˆçº§1: WebGPU (æœ€å¿«ï¼Œå®Œå…¨å¼‚æ­¥)
    if (capabilities.webgpu) {
      providerConfigs.push(['webgpu'])
    }
    
    // ä¼˜å…ˆçº§2: WebGL (è¾ƒå¿«ï¼ŒGPUåŠ é€Ÿ) - åªæœ‰åœ¨ONNX RuntimeéªŒè¯é€šè¿‡æ—¶æ‰ä½¿ç”¨
    if (capabilities.onnxWebGL) {
      providerConfigs.push(['webgl'])
      console.log('âœ… WebGLåç«¯å·²éªŒè¯å¯ç”¨')
    } else if (capabilities.webgl) {
      console.log('âš ï¸ WebGLåŸºç¡€æ”¯æŒå­˜åœ¨ï¼Œä½†ONNX Runtime WebGLåç«¯ä¸å¯ç”¨')
    }
    
    // ä¼˜å…ˆçº§3: WASM (CPUæ‰§è¡Œï¼Œå¯èƒ½é˜»å¡)
    providerConfigs.push(['wasm'])
    
    console.log('ğŸš€ æ‰§è¡Œæä¾›è€…ä¼˜å…ˆçº§:', providerConfigs)
    
    for (let i = 0; i < providerConfigs.length; i++) {
      try {
        const providers = providerConfigs[i]
        console.log(`å°è¯•é…ç½® ${i + 1}: ${providers.join(', ')}`)
        
        if (progressCallback) progressCallback(30 + (i * 20))

        // åˆ›å»ºä¼˜åŒ–çš„ä¼šè¯é€‰é¡¹
        const sessionOptions: Partial<ONNXSessionOptions> = {
          executionProviders: providers,
          // æ ¹æ®æ‰§è¡Œæä¾›è€…ä¼˜åŒ–é…ç½®
          ...(providers[0] === 'webgpu' ? {
            graphOptimizationLevel: 'all', // WebGPUæ”¯æŒå®Œæ•´ä¼˜åŒ–
            executionMode: 'parallel',     // å¹¶è¡Œæ‰§è¡Œ
            enableCpuMemArena: true,
            enableMemPattern: true
          } : providers[0] === 'webgl' ? {
            graphOptimizationLevel: 'extended', // WebGLé€‚åº¦ä¼˜åŒ–
            executionMode: 'parallel',
            enableCpuMemArena: true,
            enableMemPattern: false
          } : {
            graphOptimizationLevel: 'basic', // WASMä¿å®ˆä¼˜åŒ–
            executionMode: 'sequential',     // ä¸²è¡Œé¿å…é˜»å¡åŠ å‰§
            enableCpuMemArena: false,
            enableMemPattern: false
          })
        }
        
        console.log(`ğŸ“Š ä¼šè¯é…ç½® (${providers[0]}):`, {
          optimization: sessionOptions.graphOptimizationLevel,
          execution: sessionOptions.executionMode,
          memArena: sessionOptions.enableCpuMemArena
        })

        // å°è¯•åˆ›å»ºæ¨ç†ä¼šè¯
        this.session = await ort.InferenceSession.create(modelPath, sessionOptions)
        
        // è·å–æ¨¡å‹ä¿¡æ¯
        this.modelInfo = {
          inputNames: [...this.session.inputNames],
          outputNames: [...this.session.outputNames],
          inputShapes: {},
          outputShapes: {},
          executionProviders: providers,
          isInitialized: true
        }

        // è·å–è¾“å…¥å½¢çŠ¶ä¿¡æ¯
        try {
          for (const name of this.session.inputNames) {
            // æŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒgetInputShape
            if (this.modelInfo.inputShapes) {
              this.modelInfo.inputShapes[name] = [1, 3, 128, 128] // æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
            }
          }
        } catch (shapeError) {
          console.warn('è·å–è¾“å…¥å½¢çŠ¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼')
          if (this.modelInfo) {
            this.modelInfo.inputShapes = { input: [1, 3, 512, 512] }
          }
        }
        
        console.log('æ¨¡å‹åŠ è½½æˆåŠŸ!')
        console.log('æ¨¡å‹ä¿¡æ¯:', this.modelInfo)
        console.log('å®é™…æ‰§è¡Œæä¾›è€…:', providers)
        return // æˆåŠŸåˆ™è¿”å›
        
      } catch (error) {
        console.warn(`é…ç½® ${i + 1} å¤±è´¥:`, (error as Error).message)
        lastError = error as Error
        
        // æ¸…ç†å¤±è´¥çš„ä¼šè¯
        if (this.session) {
          try {
            this.session.release()
          } catch (e) {
            // å¿½ç•¥æ¸…ç†é”™è¯¯
          }
          this.session = null
        }
      }
    }
    
    // æ‰€æœ‰é…ç½®éƒ½å¤±è´¥
    throw new Error(`æ‰€æœ‰æ‰§è¡Œæä¾›è€…é…ç½®éƒ½å¤±è´¥ã€‚æœ€åé”™è¯¯: ${lastError?.message}`)
  }



  /**
   * æ£€æµ‹ç¡¬ä»¶èƒ½åŠ› - å¸®åŠ©é€‰æ‹©æœ€ä¼˜æ‰§è¡Œæä¾›è€…ï¼ŒåŒ…å«ONNX RuntimeéªŒè¯
   */
  private async detectHardwareCapabilities(): Promise<{
    webgpu: boolean
    webgl: boolean
    webgl2: boolean
    wasm: boolean
    simd: boolean
    threads: number
    memory: number
    onnxWebGL: boolean
  }> {
    const capabilities = {
      webgpu: false,
      webgl: false,
      webgl2: false,
      wasm: true, // ç°ä»£æµè§ˆå™¨éƒ½æ”¯æŒ
      simd: true, // WASM SIMD
      threads: navigator.hardwareConcurrency || 2,
      memory: (navigator as any).deviceMemory || 4, // GB
      onnxWebGL: false // ONNX Runtime WebGLåç«¯æ˜¯å¦å¯ç”¨
    }

    // æ£€æµ‹WebGPU
    try {
      if ('gpu' in navigator) {
        const adapter = await (navigator as any).gpu?.requestAdapter?.()
        capabilities.webgpu = !!adapter
      }
    } catch (e) {
      capabilities.webgpu = false
    }

    // æ£€æµ‹åŸºç¡€WebGL
    try {
      const canvas = document.createElement('canvas')
      const gl = canvas.getContext('webgl')
      const gl2 = canvas.getContext('webgl2')
      capabilities.webgl = !!gl
      capabilities.webgl2 = !!gl2
    } catch (e) {
      capabilities.webgl = false
      capabilities.webgl2 = false
    }

    // WebGLåŸºç¡€æ£€æµ‹é€šè¿‡åï¼Œç®€å•æ ‡è®°ä¸ºå¯ç”¨
    // å®é™…çš„ONNX Runtime WebGLéªŒè¯ä¼šåœ¨éœ€è¦æ—¶è¿›è¡Œ
    capabilities.onnxWebGL = capabilities.webgl

    return capabilities
  }



  /**
   * æ‰§è¡Œå›¾åƒè¶…åˆ†æ¨ç†
   */
  async runInference(imageData: HTMLImageElement): Promise<string> {
    if (!this.isInitialized || !this.session) {
      throw new Error('æ¨¡å‹æœªåˆå§‹åŒ–')
    }

    try {
      // ä¿å­˜åŸå›¾å°ºå¯¸ä»¥ç»´æŒå®½é«˜æ¯”
      this.originalImageSize = {
        width: imageData.naturalWidth || imageData.width,
        height: imageData.naturalHeight || imageData.height
      }
      
      console.log('åŸå›¾å°ºå¯¸:', this.originalImageSize)
      
      // æ™ºèƒ½è´¨é‡è¯„ä¼°
      const quality = ImageProcessor.assessImageQuality(imageData)
      console.log('ğŸ“Š å›¾åƒè´¨é‡è¯„ä¼°:', {
        sharpnessScore: quality.sharpnessScore?.toFixed(1),
        qualityLevel: quality.qualityLevel,
        isHighQuality: quality.isHighQuality,
        gradient: quality.gradient?.toFixed(2),
        contrast: quality.contrast?.toFixed(2),
        edgeDensity: quality.edgeDensity?.toFixed(3)
      })
      
      // ğŸ§  æ™ºèƒ½å¤„ç†ç­–ç•¥
      if (quality.isHighQuality) {
        console.log('ğŸ¯ æ£€æµ‹åˆ°é«˜è´¨é‡å›¾åƒï¼Œä½¿ç”¨æ··åˆå¢å¼ºç­–ç•¥...')
        return await this.hybridEnhancement(imageData, quality)
      } else {
        console.log('ğŸ”§ æ£€æµ‹åˆ°éœ€è¦å¢å¼ºçš„å›¾åƒï¼Œä½¿ç”¨æ ‡å‡†AIå¤„ç†...')
        return await this.standardAIEnhancement(imageData)
      }
      
    } catch (error) {
      console.error('æ¨ç†å¤±è´¥:', error)
      throw new Error(`æ¨ç†å¤±è´¥: ${(error as Error).message}`)
    }
  }

  /**
   * æ ‡å‡†AIå¢å¼ºï¼ˆé€‚ç”¨äºä½è´¨é‡å›¾åƒï¼‰- éé˜»å¡ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå¸¦é”™è¯¯é™çº§
   */
  private async standardAIEnhancement(imageData: HTMLImageElement): Promise<string> {
    // é¢„å¤„ç†å›¾åƒ - ä½¿ç”¨å¾®ä»»åŠ¡é¿å…é˜»å¡
    const inputTensor = await new Promise<ort.Tensor>((resolve, reject) => {
      setTimeout(async () => {
        try {
          const tensor = await this.preprocessImage(imageData)
          resolve(tensor)
        } catch (error) {
          reject(error)
        }
      }, 0)
    })
    
    // æ‰§è¡Œæ¨ç† - å¸¦é”™è¯¯é™çº§æœºåˆ¶
    const feeds: Record<string, ort.Tensor> = {}
    feeds[this.modelInfo!.inputNames![0]] = inputTensor
    
    return await this.runInferenceWithFallback(feeds)
  }

  /**
   * å¸¦é™çº§ç­–ç•¥çš„æ¨ç†æ‰§è¡Œ
   */
  private async runInferenceWithFallback(feeds: Record<string, ort.Tensor>): Promise<string> {
    const currentProvider = this.modelInfo?.executionProviders?.[0] || 'unknown'
    console.log(`ğŸš€ å¼€å§‹AIæ¨ç† (${currentProvider})...`)
    const startTime = performance.now()
    
    try {
      // å°è¯•å½“å‰æ‰§è¡Œæä¾›è€…
      let results: any
      if (currentProvider === 'wasm') {
        // WASMæ‰§è¡Œ - åˆ†å—å¤„ç†é¿å…é•¿æ—¶é—´é˜»å¡
        results = await this.runInferenceWithYielding(feeds)
      } else {
        // GPUæ‰§è¡Œ - ç›´æ¥æ¨ç†
        results = await this.session!.run(feeds)
      }
      
      const endTime = performance.now()
      console.log(`âœ… AIæ¨ç†æˆåŠŸ (${currentProvider})ï¼Œè€—æ—¶: ${(endTime - startTime).toFixed(2)}ms`)
      
      // åå¤„ç†ç»“æœ
      const outputTensor = results[this.modelInfo!.outputNames![0]]
      return await new Promise<string>((resolve, reject) => {
        setTimeout(async () => {
          try {
            const result = await this.postprocessImage(outputTensor)
            resolve(result)
          } catch (error) {
            reject(error)
          }
        }, 0)
      })
      
    } catch (error) {
      console.error(`âŒ ${currentProvider} æ¨ç†å¤±è´¥:`, error)
      
      // é”™è¯¯é™çº§ç­–ç•¥ - é€çº§é™çº§
      if (currentProvider === 'webgpu') {
        console.log('ğŸ”„ WebGPUå¤±è´¥ï¼Œå°è¯•é™çº§åˆ°WebGL...')
        // éªŒè¯WebGLæ˜¯å¦å¯ç”¨
        const webglAvailable = await this.verifyWebGLForONNX()
        if (webglAvailable) {
          try {
            return await this.fallbackToWebGL(feeds)
          } catch (webglError) {
            console.log('ğŸ”„ WebGLä¹Ÿå¤±è´¥ï¼Œæœ€ç»ˆé™çº§åˆ°WASM...')
            return await this.fallbackToWASM(feeds)
          }
        } else {
          console.log('ğŸ”„ WebGLä¸å¯ç”¨ï¼Œç›´æ¥é™çº§åˆ°WASM...')
          return await this.fallbackToWASM(feeds)
        }
      } else if (currentProvider === 'webgl') {
        console.log('ğŸ”„ WebGLå¤±è´¥ï¼Œå°è¯•é™çº§åˆ°WASM...')
        return await this.fallbackToWASM(feeds)
      } else {
        // WASMä¹Ÿå¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€ç»ˆé”™è¯¯
        throw new Error(`æ‰€æœ‰æ‰§è¡Œæä¾›è€…éƒ½å¤±è´¥äº†ã€‚æœ€åé”™è¯¯: ${(error as Error).message}`)
      }
    }
  }

  /**
   * é™çº§åˆ°WebGL (å‡è®¾å·²éªŒè¯WebGLå¯ç”¨)
   */
  private async fallbackToWebGL(feeds: Record<string, ort.Tensor>): Promise<string> {
    // åˆ›å»ºæ–°çš„WebGLä¼šè¯
    const sessionOptions: Partial<ONNXSessionOptions> = {
      executionProviders: ['webgl'],
      graphOptimizationLevel: 'extended',
      executionMode: 'parallel',
      enableCpuMemArena: true,
      enableMemPattern: false
    }
    
    const tempSession = await ort.InferenceSession.create(
      this.currentModelConfig!.path, 
      sessionOptions
    )
    
    console.log('âœ… WebGLé™çº§ä¼šè¯åˆ›å»ºæˆåŠŸ')
    const results = await tempSession.run(feeds)
    
    // æ¸…ç†ä¸´æ—¶ä¼šè¯
    tempSession.release()
    
    const outputTensor = results[this.modelInfo!.outputNames![0]]
    console.log('âœ… WebGLæ¨ç†å®Œæˆï¼Œå¼€å§‹åå¤„ç†...')
    return await this.postprocessImage(outputTensor)
  }

  /**
   * é™çº§åˆ°WASM
   */
  private async fallbackToWASM(feeds: Record<string, ort.Tensor>): Promise<string> {
    try {
      console.log('ğŸ”§ åˆ›å»ºWASMé™çº§ä¼šè¯...')
      
      // åˆ›å»ºæ–°çš„WASMä¼šè¯
      const sessionOptions: Partial<ONNXSessionOptions> = {
        executionProviders: ['wasm'],
        graphOptimizationLevel: 'basic',
        executionMode: 'sequential',
        enableCpuMemArena: false,
        enableMemPattern: false
      }
      
      const tempSession = await ort.InferenceSession.create(
        this.currentModelConfig!.path, 
        sessionOptions
      )
      
      console.log('âœ… WASMé™çº§ä¼šè¯åˆ›å»ºæˆåŠŸ')
      const results = await this.runInferenceWithYielding(feeds, tempSession)
      
      // æ¸…ç†ä¸´æ—¶ä¼šè¯
      tempSession.release()
      
      const outputTensor = results[this.modelInfo!.outputNames![0]]
      console.log('âœ… WASMæ¨ç†å®Œæˆï¼Œå¼€å§‹åå¤„ç†...')
      return await this.postprocessImage(outputTensor)
      
    } catch (error) {
      console.error('âŒ WASMé™çº§æœ€ç»ˆå¤±è´¥:', error)
      throw new Error(`æ‰€æœ‰æ‰§è¡Œåç«¯éƒ½å¤±è´¥äº†ã€‚WASMé”™è¯¯: ${(error as Error).message}`)
    }
  }

  /**
   * éªŒè¯WebGLæ˜¯å¦å¯ç”¨äºONNX Runtime
   */
  private async verifyWebGLForONNX(): Promise<boolean> {
    try {
      if (!this.currentModelConfig) {
        console.log('âŒ æ— æ¨¡å‹é…ç½®ï¼Œæ— æ³•éªŒè¯WebGLåç«¯')
        return false
      }
      
      console.log('ğŸ” éªŒè¯WebGLåç«¯æ˜¯å¦æ”¯æŒå½“å‰æ¨¡å‹...')
      
      // å°è¯•åˆ›å»ºä¸€ä¸ªæœ€å°é…ç½®çš„WebGLä¼šè¯
      const testOptions: Partial<ONNXSessionOptions> = {
        executionProviders: ['webgl'],
        graphOptimizationLevel: 'disabled', // æœ€å°ä¼˜åŒ–
        enableCpuMemArena: false,
        enableMemPattern: false
      }
      
      // å°è¯•åˆ›å»ºä¼šè¯ï¼Œå¦‚æœå¤±è´¥è¯´æ˜WebGLä¸å¯ç”¨
      const testSession = await ort.InferenceSession.create(
        this.currentModelConfig.path, 
        testOptions
      )
      
      // ç«‹å³é‡Šæ”¾æµ‹è¯•ä¼šè¯
      testSession.release()
      console.log('âœ… WebGLåç«¯éªŒè¯æˆåŠŸ')
      return true
      
    } catch (error) {
      const errorMsg = (error as Error).message
      console.log('âŒ WebGLåç«¯éªŒè¯å¤±è´¥:', errorMsg)
      
      // æ£€æŸ¥ç‰¹å®šçš„é”™è¯¯ç±»å‹
      if (errorMsg.includes('backend not found') || errorMsg.includes('webgl') || errorMsg.includes('WebGL')) {
        console.log('ğŸ’¡ WebGLåç«¯åœ¨å½“å‰ç¯å¢ƒä¸å¯ç”¨')
      }
      
      return false
    }
  }

  /**
   * å¸¦è®©æ­¥çš„WASMæ¨ç† - å‡å°‘ä¸»çº¿ç¨‹é˜»å¡
   */
  private async runInferenceWithYielding(
    feeds: Record<string, ort.Tensor>, 
    session?: ort.InferenceSession
  ): Promise<any> {
    const targetSession = session || this.session!
    
    return new Promise((resolve, reject) => {
      // ä½¿ç”¨requestIdleCallbackæˆ–setTimeoutæ¥è®©æ­¥ç»™ä¸»çº¿ç¨‹
      const runWithYield = () => {
        if ('requestIdleCallback' in window) {
          (window as any).requestIdleCallback(async () => {
            try {
              const results = await targetSession.run(feeds)
              resolve(results)
            } catch (error) {
              reject(error)
            }
          })
        } else {
          setTimeout(async () => {
            try {
              const results = await targetSession.run(feeds)
              resolve(results)
            } catch (error) {
              reject(error)
            }
          }, 0)
        }
      }
      runWithYield()
    })
  }

  /**
   * æ··åˆå¢å¼ºç­–ç•¥ï¼ˆé€‚ç”¨äºé«˜è´¨é‡å›¾åƒï¼‰
   */
  private async hybridEnhancement(imageData: HTMLImageElement, quality: any): Promise<string> {
    try {
      // æ‰§è¡ŒAIå¤„ç†
      const aiResult = await this.standardAIEnhancement(imageData)
      
      // åˆ›å»ºAIç»“æœçš„å›¾åƒå…ƒç´ è¿›è¡Œè´¨é‡è¯„ä¼°
      const aiImage = await ImageProcessor.loadImageFromDataURL(aiResult)
      const aiQuality = ImageProcessor.assessImageQuality(aiImage)
      
      console.log('ğŸ“ˆ è´¨é‡å¯¹æ¯”:', {
        original: quality.sharpnessScore?.toFixed(1),
        aiProcessed: aiQuality.sharpnessScore?.toFixed(1),
        improvement: ((aiQuality.sharpnessScore! - quality.sharpnessScore!) / quality.sharpnessScore! * 100).toFixed(1) + '%'
      })
      
      // å¦‚æœAIå¤„ç†åè´¨é‡ä¸‹é™è¶…è¿‡15%ï¼Œä½¿ç”¨ä¼ ç»Ÿé«˜è´¨é‡æ”¾å¤§
      if (aiQuality.sharpnessScore! < quality.sharpnessScore! * 0.85) {
        console.log('âš ï¸ AIå¤„ç†é™ä½äº†å›¾åƒè´¨é‡ï¼Œåˆ‡æ¢åˆ°é«˜è´¨é‡ä¼ ç»Ÿæ”¾å¤§')
        return this.highQualityResize(imageData)
      } else if (aiQuality.sharpnessScore! < quality.sharpnessScore! * 0.95) {
        console.log('ğŸ”€ æ··åˆAIç»“æœä¸åŸå›¾ä»¥ä¿æŒè´¨é‡')
        return await this.blendWithOriginal(imageData, aiResult, 0.7) // 70% AI + 30% åŸå›¾æ”¾å¤§
      } else {
        console.log('âœ… AIå¤„ç†æå‡äº†è´¨é‡ï¼Œä½¿ç”¨AIç»“æœ')
        return aiResult
      }
      
    } catch (error) {
      console.warn('æ··åˆå¢å¼ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜è´¨é‡ä¼ ç»Ÿæ”¾å¤§:', error)
      return this.highQualityResize(imageData)
    }
  }

  /**
   * é«˜è´¨é‡ä¼ ç»Ÿæ”¾å¤§ï¼ˆé’ˆå¯¹å·²ç»æ¸…æ™°çš„å›¾åƒï¼‰
   */
  private highQualityResize(imageData: HTMLImageElement): string {
    if (!this.originalImageSize) {
      throw new Error('ç¼ºå°‘åŸå›¾å°ºå¯¸ä¿¡æ¯')
    }
    
    const { width, height } = this.originalImageSize
    const scaleFactor = 4 // 4å€æ”¾å¤§
    
    // ä½¿ç”¨é«˜è´¨é‡æ’å€¼ç®—æ³•
    const canvas = ImageProcessor.resizeImage(
      imageData, 
      width * scaleFactor, 
      height * scaleFactor, 
      true // é«˜è´¨é‡å¹³æ»‘
    )
    
    // åº”ç”¨è½»å¾®é”åŒ–
    const ctx = canvas.getContext('2d')!
    const imageDataObj = ctx.getImageData(0, 0, canvas.width, canvas.height)
    const data = imageDataObj.data
    const sharpened = this.applySharpeningFilter(data, canvas.width, canvas.height)
    
    ctx.putImageData(sharpened, 0, 0)
    return canvas.toDataURL('image/png')
  }

  /**
   * æ··åˆAIç»“æœä¸åŸå›¾æ”¾å¤§
   */
  private async blendWithOriginal(imageData: HTMLImageElement, aiResult: string, aiWeight: number): Promise<string> {
    if (!this.originalImageSize) {
      throw new Error('ç¼ºå°‘åŸå›¾å°ºå¯¸ä¿¡æ¯')
    }
    
    const { width, height } = this.originalImageSize
    const scaleFactor = 4
    
    // åˆ›å»ºé«˜è´¨é‡çš„åŸå›¾æ”¾å¤§ç‰ˆæœ¬
    const originalResized = this.highQualityResize(imageData)
    
    // åŠ è½½ä¸¤ä¸ªå›¾åƒ
    const [originalImg, aiImg] = await Promise.all([
      ImageProcessor.loadImageFromDataURL(originalResized),
      ImageProcessor.loadImageFromDataURL(aiResult)
    ])
    
    // åˆ›å»ºæ··åˆç”»å¸ƒ
    const canvas = document.createElement('canvas')
    const ctx = canvas.getContext('2d')!
    canvas.width = width * scaleFactor
    canvas.height = height * scaleFactor
    
    // ç»˜åˆ¶åŸå›¾æ”¾å¤§ç‰ˆæœ¬
    ctx.globalAlpha = 1 - aiWeight
    ctx.drawImage(originalImg, 0, 0, canvas.width, canvas.height)
    
    // æ··åˆAIç»“æœ
    ctx.globalAlpha = aiWeight
    ctx.globalCompositeOperation = 'source-over'
    ctx.drawImage(aiImg, 0, 0, canvas.width, canvas.height)
    
    ctx.globalAlpha = 1
    ctx.globalCompositeOperation = 'source-over'
    
    return canvas.toDataURL('image/png')
  }

  /**
   * åº”ç”¨é”åŒ–æ»¤é•œ
   */
  private applySharpeningFilter(data: Uint8ClampedArray, width: number, height: number): ImageData {
    const canvas = document.createElement('canvas')
    const ctx = canvas.getContext('2d')!
    canvas.width = width
    canvas.height = height
    
    const imageData = ctx.createImageData(width, height)
    const output = imageData.data
    
    // é”åŒ–æ ¸
    const kernel = [
      0, -0.5, 0,
      -0.5, 3, -0.5,
      0, -0.5, 0
    ]
    
    // åº”ç”¨å·ç§¯
    for (let y = 1; y < height - 1; y++) {
      for (let x = 1; x < width - 1; x++) {
        for (let c = 0; c < 3; c++) { // RGBé€šé“
          let sum = 0
          for (let ky = -1; ky <= 1; ky++) {
            for (let kx = -1; kx <= 1; kx++) {
              const pixelIndex = ((y + ky) * width + (x + kx)) * 4 + c
              const kernelIndex = (ky + 1) * 3 + (kx + 1)
              sum += data[pixelIndex] * kernel[kernelIndex]
            }
          }
          const outputIndex = (y * width + x) * 4 + c
          output[outputIndex] = Math.min(255, Math.max(0, sum))
        }
        // Alphaé€šé“ä¿æŒä¸å˜
        const alphaIndex = (y * width + x) * 4 + 3
        output[alphaIndex] = data[alphaIndex]
      }
    }
    
    return imageData
  }

  /**
   * å›¾åƒé¢„å¤„ç† - æ ¹æ®æ¨¡å‹é…ç½®è‡ªé€‚åº”å¤„ç†ï¼Œå¢å¼ºSwinIRå…¼å®¹æ€§
   */
  private async preprocessImage(imageElement: HTMLImageElement): Promise<ort.Tensor> {
    return new Promise((resolve, reject) => {
      try {
        const canvas = document.createElement('canvas')
        const ctx = canvas.getContext('2d')!
        
        // æ ¹æ®æ¨¡å‹é…ç½®ç¡®å®šè¾“å…¥å°ºå¯¸
        let inputSize = this.currentModelConfig?.inputSize || 128
        const isSwinIR = this.currentModelConfig?.id?.includes('swinir')
        
        // SwinIRç‰¹æ®Šå¤„ç† - ç¡®ä¿è¾“å…¥å°ºå¯¸æ˜¯åˆç†çš„
        if (isSwinIR) {
          // ç¡®ä¿è¾“å…¥å°ºå¯¸æ˜¯8çš„å€æ•° (å¾ˆå¤šæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è¦æ±‚)
          inputSize = Math.max(64, Math.round(inputSize / 8) * 8)
          console.log(`ğŸ”§ SwinIRæ¨¡å‹ - è°ƒæ•´è¾“å…¥å°ºå¯¸ä¸º: ${inputSize}x${inputSize}`)
        }
        
        canvas.width = inputSize
        canvas.height = inputSize
        
        console.log(`ğŸ”§ é¢„å¤„ç†å›¾åƒ: ${inputSize}x${inputSize} (${this.currentModelConfig?.name || 'é»˜è®¤'})`)
        
        // åº”ç”¨é«˜è´¨é‡é‡é‡‡æ ·
        ctx.imageSmoothingEnabled = true
        ctx.imageSmoothingQuality = 'high'
        
        // ç»˜åˆ¶å¹¶ç¼©æ”¾å›¾åƒ
        ctx.drawImage(imageElement, 0, 0, inputSize, inputSize)
        const imageData = ctx.getImageData(0, 0, inputSize, inputSize)
        
        // éªŒè¯å›¾åƒæ•°æ®
        if (!imageData || imageData.data.length === 0) {
          throw new Error('æ— æ³•è·å–å›¾åƒæ•°æ®')
        }
        
        // è½¬æ¢ä¸ºRGBæ ¼å¼å¹¶å½’ä¸€åŒ–
        const pixelCount = inputSize * inputSize
        const rgbData = new Float32Array(3 * pixelCount)
        
        for (let i = 0; i < pixelCount; i++) {
          const pixelIndex = i * 4
          let r = imageData.data[pixelIndex] / 255.0
          let g = imageData.data[pixelIndex + 1] / 255.0
          let b = imageData.data[pixelIndex + 2] / 255.0
          
          // SwinIRç‰¹æ®Šé¢„å¤„ç†
          if (isSwinIR) {
            // ç¡®ä¿å€¼åœ¨[0,1]èŒƒå›´å†…ï¼Œå¹¶åšè½»å¾®å¯¹æ¯”åº¦å¢å¼º
            r = Math.min(1.0, Math.max(0.0, r * 1.02)) // è½»å¾®å¢å¼º
            g = Math.min(1.0, Math.max(0.0, g * 1.02))
            b = Math.min(1.0, Math.max(0.0, b * 1.02))
          } else {
            // å…¶ä»–æ¨¡å‹æ ‡å‡†å½’ä¸€åŒ–
            r = Math.min(1.0, Math.max(0.0, r))
            g = Math.min(1.0, Math.max(0.0, g))
            b = Math.min(1.0, Math.max(0.0, b))
          }
          
          // RGBé€šé“æ’åˆ— [1, 3, H, W] - NCHWæ ¼å¼
          rgbData[i] = r                                    // R
          rgbData[i + pixelCount] = g                       // G  
          rgbData[i + 2 * pixelCount] = b                   // B
        }
        
        // éªŒè¯å¼ é‡æ•°æ®
        if (rgbData.some(val => !isFinite(val) || val < 0 || val > 1)) {
          throw new Error('å¼ é‡æ•°æ®åŒ…å«æ— æ•ˆå€¼')
        }
        
        // åˆ›å»ºè¾“å…¥å¼ é‡ [1, 3, H, W]
        const tensorShape = [1, 3, inputSize, inputSize]
        const inputTensor = new ort.Tensor('float32', rgbData, tensorShape)
        
        console.log(`ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: [${inputTensor.dims.join(', ')}], æ•°æ®èŒƒå›´: [${Math.min(...rgbData).toFixed(3)}, ${Math.max(...rgbData).toFixed(3)}]`)
        
        // é¢å¤–éªŒè¯å¼ é‡
        if (inputTensor.dims.some(dim => dim <= 0)) {
          throw new Error(`æ— æ•ˆçš„å¼ é‡å½¢çŠ¶: [${inputTensor.dims.join(', ')}]`)
        }
        
        resolve(inputTensor)
      } catch (error) {
        console.error('é¢„å¤„ç†å¤±è´¥:', error)
        reject(error)
      }
    })
  }

  /**
   * å›¾åƒåå¤„ç†
   */
  private async postprocessImage(outputTensor: ort.Tensor): Promise<string> {
    return new Promise(async (resolve) => {
      const outputData = outputTensor.data as Float32Array
      const dims = outputTensor.dims
      
      // è°ƒè¯•è¾“å‡ºå¼ é‡ä¿¡æ¯
      console.log('è¾“å‡ºå¼ é‡ç»´åº¦:', dims)
      
      let aiWidth: number, aiHeight: number
      
      // å¤„ç†ä¸åŒçš„å¼ é‡ç»´åº¦æ ¼å¼
      if (dims.length === 4) {
        // 4ç»´å¼ é‡: [batch, channels, height, width]
        aiWidth = Math.floor(Number(dims[3]))
        aiHeight = Math.floor(Number(dims[2]))
      } else if (dims.length === 3) {
        // 3ç»´å¼ é‡: [channels, height, width] 
        aiWidth = Math.floor(Number(dims[2]))
        aiHeight = Math.floor(Number(dims[1]))
      } else {
        throw new Error(`ä¸æ”¯æŒçš„å¼ é‡ç»´åº¦: ${dims.length}D, ç»´åº¦: ${dims}`)
      }
      
      console.log('AIè¾“å‡ºå°ºå¯¸:', { aiWidth, aiHeight })
      
      // éªŒè¯AIè¾“å‡ºå°ºå¯¸ä¸ºæœ‰æ•ˆå€¼
      if (!Number.isInteger(aiWidth) || !Number.isInteger(aiHeight) || aiWidth <= 0 || aiHeight <= 0) {
        throw new Error(`æ— æ•ˆçš„AIè¾“å‡ºå°ºå¯¸: ${aiWidth}x${aiHeight}`)
      }
      
      // åˆ›å»ºAIè¾“å‡ºçš„ä¸´æ—¶canvas
      const aiCanvas = document.createElement('canvas')
      const aiCtx = aiCanvas.getContext('2d')!
      aiCanvas.width = aiWidth
      aiCanvas.height = aiHeight
      
      const aiImageData = aiCtx.createImageData(aiWidth, aiHeight)
      const pixelCount = aiWidth * aiHeight
      
      // å°†å¼ é‡æ•°æ®è½¬æ¢ä¸ºRGBAæ ¼å¼
      for (let i = 0; i < pixelCount; i++) {
        const outputIndex = i * 4
        
        // ä»å½’ä¸€åŒ–å€¼è½¬æ¢å›[0,255]èŒƒå›´å¹¶é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
        const r = Math.min(255, Math.max(0, Math.round(outputData[i] * 255)))
        const g = Math.min(255, Math.max(0, Math.round(outputData[i + pixelCount] * 255)))
        const b = Math.min(255, Math.max(0, Math.round(outputData[i + 2 * pixelCount] * 255)))
        
        aiImageData.data[outputIndex] = r     // R
        aiImageData.data[outputIndex + 1] = g // G
        aiImageData.data[outputIndex + 2] = b // B
        aiImageData.data[outputIndex + 3] = 255 // A
      }
      
      aiCtx.putImageData(aiImageData, 0, 0)
      
      // å¦‚æœæœ‰åŸå›¾å°ºå¯¸ä¿¡æ¯ï¼Œè°ƒæ•´è¾“å‡ºä»¥ä¿æŒåŸå›¾å®½é«˜æ¯”
      if (this.originalImageSize) {
        const { width: originalWidth, height: originalHeight } = this.originalImageSize
        
        // æ ¹æ®æ¨¡å‹é…ç½®è®¡ç®—å¢å¼ºå€æ•°
        const modelInputSize = this.currentModelConfig?.inputSize || 128
        const enhancementFactor = aiWidth / modelInputSize
        
        // è®¡ç®—ç›®æ ‡è¾“å‡ºå°ºå¯¸ï¼ˆä¿æŒåŸå›¾æ¯”ä¾‹ï¼Œåº”ç”¨å¢å¼ºå€æ•°ï¼‰
        const targetWidth = Math.round(originalWidth * enhancementFactor)
        const targetHeight = Math.round(originalHeight * enhancementFactor)
        
        console.log('ğŸ¯ è¾“å‡ºå°ºå¯¸è®¡ç®—:', { 
          targetWidth, 
          targetHeight, 
          enhancementFactor,
          modelName: this.currentModelConfig?.name || 'æœªçŸ¥',
          modelInputSize,
          aiOutputSize: `${aiWidth}x${aiHeight}`
        })
        
        // åˆ›å»ºAIè¾“å‡ºçš„ä¸´æ—¶å›¾åƒå…ƒç´ 
        const tempImage = new Image()
        tempImage.onload = () => {
          // ä½¿ç”¨ImageProcessorè°ƒæ•´å°ºå¯¸
          const finalCanvas = ImageProcessor.resizeImage(tempImage, targetWidth, targetHeight, true)
          resolve(finalCanvas.toDataURL('image/png'))
        }
        tempImage.src = aiCanvas.toDataURL()
      } else {
        // å¦‚æœæ²¡æœ‰åŸå›¾å°ºå¯¸ä¿¡æ¯ï¼Œç›´æ¥è¿”å›AIè¾“å‡º
        console.warn('æ²¡æœ‰åŸå›¾å°ºå¯¸ä¿¡æ¯ï¼Œä½¿ç”¨AIåŸå§‹è¾“å‡º')
        resolve(aiCanvas.toDataURL('image/png'))
      }
    })
  }

  /**
   * è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯
   */
  getModelInfo(): ModelInfo {
    const baseInfo: ModelInfo = {
      isInitialized: this.isInitialized,
      inputNames: this.modelInfo?.inputNames || [],
      outputNames: this.modelInfo?.outputNames || [],
      inputShapes: this.modelInfo?.inputShapes || {},
      outputShapes: this.modelInfo?.outputShapes || {},
      executionProviders: this.modelInfo?.executionProviders || []
    }
    
    if (this.currentModelConfig) {
      baseInfo.modelName = this.currentModelConfig.name
      baseInfo.modelDescription = this.currentModelConfig.description
      baseInfo.scaleFactor = this.currentModelConfig.scaleFactor
      baseInfo.inputSize = this.currentModelConfig.inputSize
    }
    
    return baseInfo
  }

  /**
   * é‡Šæ”¾èµ„æº
   */
  dispose(): void {
    if (this.session) {
      this.session.release()
      this.session = null
    }
    this.isInitialized = false
    this.modelInfo = null
    this.originalImageSize = null
    this.currentModelConfig = null
    console.log('ğŸ§¹ ONNXæ¨ç†èµ„æºå·²é‡Šæ”¾')
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const onnxInference = new ONNXInference()
